\thispagestyle{acknowledgements}
\section*{Abstract}
\addcontentsline{toc}{section}{Abstract}

\textbf{\textit{Reinforcement Learning in complex goal-based robotics environments which involves interaction, manipulation and sparse rewards has always remained a challenge. Exploration is a large part of reinforcement learning which uses a big chunk of the training time. Random exploration cannot solve complex manipulation tasks and a well-engineered reward function can result in sub-optimal performance. This work investigates the combination of behaviour cloning and reinforcement learning to accelerate the training of an autonomous agent without compromising on performance and generalization in the Fetch Robotics Environments. Behaviour cloning is the simplest form of imitation learning where the agent uses expert demonstrations to learn actions for performing tasks. Humans often use this form of imitation by observing others better at a given task and applying similar methods to achieve the same goal. The same principle is extended and combined with the reinforcement learning agent. This paper proposes a form of behaviour cloning to overcome this exploration phase and perform more meaningful actions early on, along with a simple yet informative reward scheme to accelerate learning. This proposed method achieves considerable speedup compared to previous baselines using a lesser number of demonstrations containing success, failure and noisy examples. The agent is not restricted by these demonstrations. It can outperform the demonstrator while developing new behaviours.}}
