\thispagestyle{acknowledgements}
\section*{Abstract}
\addcontentsline{toc}{section}{Abstract}

\textbf{\textit{Reinforcement Learning in complex goal-based robotics environments which involves interaction and manipulation with sparse rewards has always remained a challenge. Exploration is a large part of reinforcement learning which uses a big chunk of the training time. Random exploration cannot solve complex manipulation tasks and a well-engineered reward function can result in sub-optimal performance. This paper investigates the combination of behaviour cloning and reinforcement learning with a simple yet informative reward function to accelerate the training of an autonomous agent without compromising on performance and generalization in the Fetch Robotics Environments. Behaviour cloning is the simplest form of imitation learning where the agent uses expert demonstrations to learn actions for performing tasks. Humans often use this form of imitation by observing others better at a given task and applying similar methods to achieve the same goal. This principle is extended and combined with the reinforcement learning agent to help accelerate the training. This paper proposes a form of behaviour cloning to overcome this exploration phase and perform more meaningful actions early on, along with a simple yet informative reward scheme to accelerate learning. This proposed method achieves considerable speedup compared to previous baselines using a lesser number of demonstrations containing both success and failure examples. The agent is not restricted by the expert demonstrations and is even able to outperform the demo agent.}}